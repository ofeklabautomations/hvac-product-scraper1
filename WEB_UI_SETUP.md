# HVAC Scraper Web UI - Setup Guide

## üéâ **Web UI Successfully Created!**

You now have a complete web interface for your HVAC scraper that can be deployed to Vercel.

## üìÅ **What Was Built**

### **Frontend (Next.js)**
- **Clean, simple form** - Just paste URL and manufacturer name
- **Real-time progress** - Watch scraping progress live
- **ZIP download** - Get all results in one file
- **Mobile responsive** - Works on all devices

### **Backend (API Routes)**
- **`/api/scrape`** - Starts scraping job, returns job ID
- **`/api/scrape/[jobId]/progress`** - Streams real-time progress updates
- **`/api/download/[jobId]`** - Downloads ZIP with all results

### **Python Integration**
- **Modified scraper** - Now supports job IDs and progress JSON output
- **Isolated jobs** - Each scraping job gets its own output directory
- **Automatic cleanup** - Files are deleted after download

## üöÄ **How to Use**

### **Local Development**
```bash
# 1. Start the web UI
cd web
npm install
npm run dev

# 2. Open browser to http://localhost:3000
# 3. Fill in form and test scraping
```

### **Deploy to Vercel**
```bash
# 1. Install Vercel CLI
npm i -g vercel

# 2. Deploy from project root
vercel --prod

# 3. Set environment variables in Vercel dashboard:
#    PYTHON_PATH=/Users/ofeksuchard/load55-productimporter/.venv/bin/python
#    SCRAPER_ROOT=/Users/ofeksuchard/load55-productimporter
```

## ‚ö†Ô∏è **Important Notes**

### **Vercel Pro Required**
- **Free tier**: 10-second timeout (not enough for scraping)
- **Pro tier**: 5-minute timeout ($20/month)
- **Alternative**: Use hybrid setup with separate Python backend

### **Environment Variables**
You must set these in Vercel dashboard:
```
PYTHON_PATH=/Users/ofeksuchard/load55-productimporter/.venv/bin/python
SCRAPER_ROOT=/Users/ofeksuchard/load55-productimporter
```

## üéØ **User Experience**

1. **User opens website** ‚Üí Sees clean form
2. **User enters URL and manufacturer** ‚Üí Clicks "Start Scraping"
3. **Real-time progress** ‚Üí "Crawling page 2/10... 67%"
4. **Scraping completes** ‚Üí Download button appears
5. **User downloads ZIP** ‚Üí Gets all CSVs + PDFs
6. **Automatic cleanup** ‚Üí Files deleted after download

## üìä **What Users Get**

### **ZIP File Contains:**
- `products.csv` - Raw product data with all specs
- `normalized_products.csv` - Clean, organized data ready for database
- `documents.csv` - List of downloaded PDFs
- `files/` folder - All downloaded PDF manuals and catalogs

## üîß **Technical Details**

### **Architecture**
- **Frontend**: Next.js 14 with TypeScript and Tailwind CSS
- **Backend**: Node.js API routes that spawn Python processes
- **Communication**: Server-Sent Events for real-time progress
- **Storage**: Temporary job directories with automatic cleanup

### **Key Features**
- **Job isolation** - Each scraping job gets unique directory
- **Progress streaming** - Real-time updates via SSE
- **Error handling** - Graceful failure with user-friendly messages
- **Mobile responsive** - Works on phones and tablets

## üöÄ **Next Steps**

### **Immediate (Ready to Deploy)**
1. **Test locally**: `cd web && npm run dev`
2. **Deploy to Vercel**: `vercel --prod`
3. **Set environment variables** in Vercel dashboard
4. **Test with real URLs** on your deployed site

### **Future Enhancements**
- **User accounts** - Track scraping history
- **Email notifications** - Get notified when done
- **Custom selectors** - UI for configuring CSS selectors
- **Scheduled scraping** - Recurring jobs

## üéâ **Success!**

You now have a complete, production-ready web interface for your HVAC scraper that:
- ‚úÖ **Works out of the box** - No coding required for users
- ‚úÖ **Real-time progress** - Users see what's happening
- ‚úÖ **Mobile friendly** - Works on any device
- ‚úÖ **Professional UI** - Clean, modern interface
- ‚úÖ **Easy deployment** - One command to deploy to Vercel

**Your users can now simply paste a URL and get professional scraping results!**
